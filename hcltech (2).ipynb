{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":13916966,"sourceType":"datasetVersion","datasetId":8867719}],"dockerImageVersionId":31192,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install imbalanced-learn==0.11.0\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-11-29T10:11:04.622877Z","iopub.execute_input":"2025-11-29T10:11:04.623581Z","iopub.status.idle":"2025-11-29T10:11:07.927936Z","shell.execute_reply.started":"2025-11-29T10:11:04.623546Z","shell.execute_reply":"2025-11-29T10:11:07.926912Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: imbalanced-learn==0.11.0 in /usr/local/lib/python3.11/dist-packages (0.11.0)\nRequirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.11/dist-packages (from imbalanced-learn==0.11.0) (1.26.4)\nRequirement already satisfied: scipy>=1.5.0 in /usr/local/lib/python3.11/dist-packages (from imbalanced-learn==0.11.0) (1.15.3)\nRequirement already satisfied: scikit-learn>=1.0.2 in /usr/local/lib/python3.11/dist-packages (from imbalanced-learn==0.11.0) (1.2.2)\nRequirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from imbalanced-learn==0.11.0) (1.5.2)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from imbalanced-learn==0.11.0) (3.6.0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17.3->imbalanced-learn==0.11.0) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17.3->imbalanced-learn==0.11.0) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17.3->imbalanced-learn==0.11.0) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17.3->imbalanced-learn==0.11.0) (2025.3.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17.3->imbalanced-learn==0.11.0) (2022.3.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17.3->imbalanced-learn==0.11.0) (2.4.1)\nRequirement already satisfied: onemkl-license==2025.3.0 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17.3->imbalanced-learn==0.11.0) (2025.3.0)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17.3->imbalanced-learn==0.11.0) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17.3->imbalanced-learn==0.11.0) (2022.3.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.17.3->imbalanced-learn==0.11.0) (1.4.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.17.3->imbalanced-learn==0.11.0) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.17.3->imbalanced-learn==0.11.0) (2024.2.0)\n","output_type":"stream"}],"execution_count":11},{"cell_type":"code","source":"# ============================================================\n# SCRIPT 1: segmentation_creator.py\n# Creates labeled dataset (critical / habitual / occasional)\n# ============================================================\n\nimport pandas as pd\nimport numpy as np\n\npd.set_option(\"display.max_columns\", 200)\npd.set_option(\"display.width\", 200)\n\n# ------------------------------------------------------------\n# 1. LOAD ALL 5 TABLES FROM IBM TELCO DATA\n# ------------------------------------------------------------\nbase_path = \"/kaggle/input/hcldata\"\n\ndemo = pd.read_csv(f\"{base_path}/Telco_customer_churn_demographics.csv\")\nloc  = pd.read_csv(f\"{base_path}/Telco_customer_churn_location.csv\")\npop  = pd.read_csv(f\"{base_path}/Telco_customer_churn_population.csv\")\nserv = pd.read_csv(f\"{base_path}/Telco_customer_churn_services.csv\")\nstat = pd.read_csv(f\"{base_path}/Telco_customer_churn_status.csv\")\n\nprint(\"Loaded Shapes:\")\nprint(\"Demographics:\", demo.shape)\nprint(\"Location    :\", loc.shape)\nprint(\"Population  :\", pop.shape)\nprint(\"Services    :\", serv.shape)\nprint(\"Status      :\", stat.shape)\n\n# ------------------------------------------------------------\n# 2. MERGE TABLES ON CUSTOMER ID\n# ------------------------------------------------------------\ndf = (\n    serv.merge(stat, on=\"Customer ID\", suffixes=(\"_serv\", \"_status\"))\n        .merge(demo, on=\"Customer ID\")\n        .merge(loc, on=\"Customer ID\", suffixes=(\"_demo\", \"_loc\"))\n)\n\ndf = df.merge(pop, on=\"Zip Code\", how=\"left\")\n\nprint(\"\\nMerged Shape:\", df.shape)\n\n# ------------------------------------------------------------\n# 3. CLEANING\n# ------------------------------------------------------------\n# Clean object columns\nfor col in df.select_dtypes(include=\"object\").columns:\n    df[col] = df[col].astype(str).str.strip()\n\n# Numeric conversions\nnumeric_candidates = [\n    \"Tenure in Months\",\"Avg Monthly Long Distance Charges\",\n    \"Avg Monthly GB Download\",\"Monthly Charge\",\"Total Charges\",\n    \"Total Refunds\",\"Total Extra Data Charges\",\n    \"Total Long Distance Charges\",\"Churn Score\",\"CLTV\",\n    \"Population\",\"Number of Dependents\",\"Number of Referrals\"\n]\n\nfor col in numeric_candidates:\n    if col in df.columns:\n        df[col] = pd.to_numeric(df[col], errors=\"coerce\")\n\n# Fill numeric NaN\nnum_cols = df.select_dtypes(include=[\"int64\",\"float64\"]).columns\ndf[num_cols] = df[num_cols].fillna(df[num_cols].median())\n\nprint(\"\\nClean Columns:\", len(df.columns))\n\n# ------------------------------------------------------------\n# 4. RULE-BASED SEGMENTATION\n# ------------------------------------------------------------\ndf_seg = df.copy()\n\ndf_seg[\"Churn Value\"] = df_seg.get(\"Churn Value\", 0)\ndf_seg[\"Churn Score\"] = df_seg.get(\"Churn Score\", 0)\n\n# Quantiles\ntotal_q60   = df_seg[\"Total Charges\"].quantile(0.60)\ncltv_q60    = df_seg[\"CLTV\"].quantile(0.60)\nchurn_q50   = df_seg[\"Churn Score\"].quantile(0.50)\nchurn_q70   = df_seg[\"Churn Score\"].quantile(0.70)\nrefund_q60  = df_seg[\"Total Refunds\"].quantile(0.60)\nextra_q60   = df_seg[\"Total Extra Data Charges\"].quantile(0.60)\n\nsegments = []\n\nfor _, r in df_seg.iterrows():\n\n    # -------------------------------\n    # 1. CRITICAL CUSTOMER RULES\n    # -------------------------------\n    family_like = (\n        (r[\"Dependents\"] == \"Yes\") or\n        (r[\"Multiple Lines\"] == \"Yes\") or\n        (r[\"Number of Dependents\"] > 0)\n    )\n\n    high_value = (\n        (r[\"Total Charges\"] >= total_q60) or\n        (r[\"CLTV\"] >= cltv_q60)\n    )\n\n    low_risk = (r[\"Churn Score\"] <= churn_q50)\n\n    if sum([family_like, high_value, low_risk]) >= 2:\n        segments.append(\"critical\")\n        continue\n\n    # -------------------------------\n    # 2. HABITUAL DEFAULTER\n    # -------------------------------\n    high_churn = (r[\"Churn Score\"] >= churn_q70) or (r[\"Churn Value\"] == 1)\n    financial_instability = (\n        (r[\"Total Refunds\"] >= refund_q60) or\n        (r[\"Total Extra Data Charges\"] >= extra_q60)\n    )\n\n    if high_churn and financial_instability:\n        segments.append(\"habitual_defaulter\")\n        continue\n\n    # -------------------------------\n    # 3. OCCASIONAL DEFAULTER\n    # -------------------------------\n    segments.append(\"occasional_defaulter\")\n\ndf_seg[\"segment\"] = segments\n\nprint(\"\\nFinal Segmentation Distribution:\")\nprint(df_seg[\"segment\"].value_counts())\n\n# ------------------------------------------------------------\n# 5. SAVE FINAL LABELED DATASET\n# ------------------------------------------------------------\noutput_path = \"/kaggle/working/final.csv\"\ndf_seg.to_csv(output_path, index=False)\n\nprint(\"\\nSaved labeled dataset to:\")\nprint(output_path)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-29T11:02:20.633751Z","iopub.execute_input":"2025-11-29T11:02:20.634368Z","iopub.status.idle":"2025-11-29T11:02:21.379553Z","shell.execute_reply.started":"2025-11-29T11:02:20.634336Z","shell.execute_reply":"2025-11-29T11:02:21.378782Z"}},"outputs":[{"name":"stdout","text":"Loaded Shapes:\nDemographics: (7043, 9)\nLocation    : (7043, 10)\nPopulation  : (1671, 3)\nServices    : (7043, 31)\nStatus      : (7043, 12)\n\nMerged Shape: (7043, 61)\n\nClean Columns: 61\n\nFinal Segmentation Distribution:\nsegment\ncritical                4058\nhabitual_defaulter      1716\noccasional_defaulter    1269\nName: count, dtype: int64\n\nSaved labeled dataset to:\n/kaggle/working/final.csv\n","output_type":"stream"}],"execution_count":15}]}