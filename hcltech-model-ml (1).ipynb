{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":13918323,"sourceType":"datasetVersion","datasetId":8868740},{"sourceId":13918694,"sourceType":"datasetVersion","datasetId":8869025}],"dockerImageVersionId":31192,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# ============================================================\n# SCRIPT 2: xgboost_trainer.py\n# Train XGBoost on rule-generated segments\n# ============================================================\n\nimport pandas as pd\nimport numpy as np\n\nfrom sklearn.model_selection import train_test_split, cross_val_score\nfrom sklearn.preprocessing import OneHotEncoder, StandardScaler, LabelEncoder\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.metrics import classification_report, confusion_matrix, accuracy_score, f1_score\n\nfrom xgboost import XGBClassifier\nimport joblib\n\n# ------------------------------------------------------------\n# 1. LOAD LABELED CSV FROM SCRIPT 1\n# ------------------------------------------------------------\ndf = pd.read_csv(\"/kaggle/input/hcl-ml/final.csv\")\n\n# ------------------------------------------------------------\n# 2. REMOVE LEAKAGE COLUMNS\n# ------------------------------------------------------------\nleakage_cols = [\n    \"segment\", \"segment_encoded\",\n    \"Churn Label\", \"Churn Value\", \"Churn Score\",\n    \"Churn Category\", \"Churn Reason\", \"Customer Status\",\n    \"Customer ID\", \"Service ID\", \"Status ID\", \"Location ID\",\n    \"ID\", \"Lat Long\"\n]\n\nX = df.drop(columns=[c for c in leakage_cols if c in df.columns])\ny = df[\"segment\"]\n\n# ------------------------------------------------------------\n# 3. ENCODE TARGET LABELS (0/1/2)\n# ------------------------------------------------------------\nle = LabelEncoder()\ny = le.fit_transform(y)\n\nprint(\"Label mapping:\", dict(zip(le.classes_, le.transform(le.classes_))))\n\n# ------------------------------------------------------------\n# 4. COLUMN TYPES\n# ------------------------------------------------------------\ncategorical_cols = X.select_dtypes(include=[\"object\"]).columns.tolist()\nnumeric_cols = X.select_dtypes(include=[\"int64\",\"float64\"]).columns.tolist()\n\n# ------------------------------------------------------------\n# 5. PREPROCESSING PIPELINE\n# ------------------------------------------------------------\npreprocessor = ColumnTransformer(\n    transformers=[\n        (\"cat\", OneHotEncoder(handle_unknown=\"ignore\"), categorical_cols),\n        (\"num\", StandardScaler(), numeric_cols),\n    ]\n)\n\n# ------------------------------------------------------------\n# 6. XGBOOST MODEL\n# ------------------------------------------------------------\nxgb_model = XGBClassifier(\n    n_estimators=300,\n    max_depth=6,\n    learning_rate=0.05,\n    subsample=0.8,\n    colsample_bytree=0.8,\n    eval_metric=\"mlogloss\"\n)\n\npipeline = Pipeline(steps=[\n    (\"preprocess\", preprocessor),\n    (\"model\", xgb_model)\n])\n\n# ------------------------------------------------------------\n# 7. TRAIN/TEST SPLIT\n# ------------------------------------------------------------\nX_train, X_test, y_train, y_test = train_test_split(\n    X, y,\n    test_size=0.25,\n    random_state=42,\n    stratify=y\n)\n\n# ------------------------------------------------------------\n# 8. TRAIN MODEL\n# ------------------------------------------------------------\npipeline.fit(X_train, y_train)\n\n# ------------------------------------------------------------\n# 9. PREDICT & EVALUATE\n# ------------------------------------------------------------\ny_pred = pipeline.predict(X_test)\n\nprint(\"\\n=========== MODEL SCORES ===========\")\nprint(\"Accuracy:\", accuracy_score(y_test, y_pred))\nprint(\"Macro F1:\", f1_score(y_test, y_pred, average='macro'))\nprint(\"Weighted F1:\", f1_score(y_test, y_pred, average='weighted'))\n\nprint(\"\\nClassification Report:\")\nprint(classification_report(y_test, y_pred))\n\nprint(\"\\nConfusion Matrix:\")\nprint(confusion_matrix(y_test, y_pred))\n\n# ------------------------------------------------------------\n# 10. SAVE MODEL + LABEL ENCODER\n# ------------------------------------------------------------\njoblib.dump(pipeline, \"/kaggle/working/telco_xgb_model.pkl\")\njoblib.dump(le, \"/kaggle/working/label_encoder.pkl\")\n\nprint(\"\\nModel saved successfully!\")\n","metadata":{"_uuid":"ce059623-8737-4e7d-8b51-50ad50ba68fa","_cell_guid":"2177c1db-0a2d-4e64-88ab-a486284795a0","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2025-11-29T11:05:50.953385Z","iopub.execute_input":"2025-11-29T11:05:50.953777Z","iopub.status.idle":"2025-11-29T11:05:53.969688Z","shell.execute_reply.started":"2025-11-29T11:05:50.953750Z","shell.execute_reply":"2025-11-29T11:05:53.969032Z"}},"outputs":[{"name":"stdout","text":"Label mapping: {'critical': 0, 'habitual_defaulter': 1, 'occasional_defaulter': 2}\n\n=========== MODEL SCORES ===========\nAccuracy: 0.8580352072685974\nMacro F1: 0.8176682326367466\nWeighted F1: 0.8529139192032125\n\nClassification Report:\n              precision    recall  f1-score   support\n\n           0       0.85      0.97      0.91      1015\n           1       0.91      0.71      0.80       429\n           2       0.81      0.69      0.74       317\n\n    accuracy                           0.86      1761\n   macro avg       0.86      0.79      0.82      1761\nweighted avg       0.86      0.86      0.85      1761\n\n\nConfusion Matrix:\n[[987  21   7]\n [ 79 305  45]\n [ 89   9 219]]\n\nModel saved successfully!\n","output_type":"stream"}],"execution_count":8}]}